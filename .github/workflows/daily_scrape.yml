name: Daily Scrape

on:
  schedule:
    # Run every 6 hours (approx 4 times a day)
    # You can adjust this cron expression as needed.
    # UTC time.
    - cron: "0 8,20 * * *"
  workflow_dispatch: # Allows manual trigger

permissions:
  contents: write

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python -m playwright install --with-deps chromium

      - name: Run Scraper
        env:
          BUBLOX_EMAIL: ${{ secrets.BUBLOX_EMAIL }}
          BUBLOX_PASSWORD: ${{ secrets.BUBLOX_PASSWORD }}
        run: |
          python main.py

      - name: Commit State Changes
        if: success()
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"

          # Check if last_run.json changed
          if [[ -n $(git status --porcelain last_run.json) ]]; then
            git add last_run.json
            git commit -m "Update last_run.json state [skip ci]"
            git push
          else
            echo "No changes to last_run.json"
          fi

      - name: Upload Debug Screenshots
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshots
          path: "**/*.png"
