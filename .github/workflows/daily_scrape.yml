name: Daily Scrape

on:
  schedule:
    # Backup: GitHub Actions cron (unreliable)
    - cron: "*/30 * * * *"
  workflow_dispatch: # Allows manual trigger
  repository_dispatch: # Allows external trigger (Google Cloud Scheduler)
    types: [run-scraper]

permissions:
  contents: write

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          python -m playwright install --with-deps chromium

      - name: Run Scraper
        env:
          BUBLOX_EMAIL: kevintorresloyola@gmail.com
          BUBLOX_PASSWORD: Kkdvk123
        run: |
          python main.py

      - name: Commit State Changes
        if: success()
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"

          # Check if last_run.json changed
          if [[ -n $(git status --porcelain last_run.json) ]]; then
            git add last_run.json
            git commit -m "Update last_run.json state [skip ci]"
            git push
          else
            echo "No changes to last_run.json"
          fi
